apiVersion: "kafka.strimzi.io/v1beta2"
kind: KafkaConnector
metadata:
  # connector name
  name: "ingest-src-oracle-jdbc-handshake-avro-v9"
  labels:
    # kafka connect [cluster] name
    strimzi.io/cluster: connect-cluster
spec:
  class: io.confluent.connect.jdbc.JdbcSourceConnector
  tasksMax: 1
  config:
    ### Schema and avro configuration ###
    key.converter: io.confluent.connect.avro.AvroConverter
    key.converter.schema.registry.url: "http://schema-registry-cp-schema-registry:8081"
    value.converter: io.confluent.connect.avro.AvroConverter
    value.converter.schema.registry.url: "http://schema-registry-cp-schema-registry:8081"

    ### Database connection configuration ###
    connection.url: "jdbc:oracle:thin:@//oracle_url:1521/database"
    connection.user: "user_oracle"
    connection.password: "user_oracle_password"
    # Falta credenciais de lab
    # connection.url: "${file:/opt/kafka/external-configuration/connector-config-oracle/connector.properties:oracle_url}"
    # connection.user: "${file:/opt/kafka/external-configuration/connector-config-oracle/connector.properties:oracle_username}"
    # connection.password: "${file:/opt/kafka/external-configuration/connector-config-oracle/connector.properties:oracle_password}"
    connection.attempts: "2"

    ### Batch config ###
    producer.override.batch.size: 327680  
    producer.override.linger.ms: 100

    ### Table, query and topic config ###
    table.types: "TABLE"
    # table.whitelist: oracle.database.schema.table
    numeric.mapping: "best_fit"
    query: "SELECT CAST(ACTION_ID AS NUMERIC(8,0)) AS ACTION_ID, LANGUAGE, SOURCE_LANG, DESCRIPTION, CAST(CREATED_BY AS NUMERIC(8,0)) AS CREATED_BY, CREATION_DATE, CAST(LAST_UPDATED_BY AS NUMERIC(8,0)) AS LAST_UPDATED_BY, LAST_UPDATE_DATE, CAST(LAST_UPDATE_LOGIN AS NUMERIC(8,0)) AS LAST_UPDATE_LOGIN, ZD_EDITION_NAME, ZD_SYNC FROM schema.table"
    topic.prefix: "oracle.database.schema.table"
    # topic.creation.default.partitions: 3
    # topic.creation.default.replication.factor: 3

    ### Handling events ###
    mode: "incrementing"
    incrementing.column.name: "ACTION_ID"
    validate.non.null: "false"

    ##### SMT - Simple Message Transform - https://docs.confluent.io/5.5.4/connect/transforms/index.html #####
    transforms: "createKey,extractInt,InsertTopic,InsertSourceDetails" # informar quais transformações realizar
    transforms.createKey.type: "org.apache.kafka.connect.transforms.ValueToKey" # copie o valor de um campo para a key da mensagem
    transforms.createKey.fields: "ACTION_ID" # lista de campos da tabela que vai virar key
    transforms.extractInt.type: "org.apache.kafka.connect.transforms.ExtractField$Key" # extraia apenas a parte integer do campo
    transforms.extractInt.field: "ACTION_ID" # qual campo o integer vai ser extraido
    transforms.InsertTopic.type: "org.apache.kafka.connect.transforms.InsertField$Value" # insira o nome do tópico na mensagem
    transforms.InsertTopic.topic.field: "messagetopic" # nome do campo contendo o nome do topico
    transforms.InsertSourceDetails.type: "org.apache.kafka.connect.transforms.InsertField$Value" # insira um campo com informações da origem da mensagem
    transforms.InsertSourceDetails.static.field: "messagesource" # nome do campo
    transforms.InsertSourceDetails.static.value: "oracle" # valor estatico para o campo