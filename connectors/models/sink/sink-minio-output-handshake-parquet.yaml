apiVersion: "kafka.strimzi.io/v1beta2"
kind: "KafkaConnector"
metadata:
  # connector name
  name: "sink-minio-output-handshake-parquet-v1"
  labels:
    # kafka connect cluster name
    strimzi.io/cluster: connect-cluster
spec:
  class: io.confluent.connect.s3.S3SinkConnector
  tasksMax: 1
  config:
    key.converter.schemas.enable: "false"
    value.converter.schemas.enable: "false"
    topics: "src-oracle-handshake-json"
    s3.bucket.name: "kafka"
    s3.part.size: 5242880
    flush.size: 500
    rotate.schedule.interval.ms: 18000
    store.url: "http://minio.namespace.svc.cluster.local:9000"
    aws.access.key.id: "500U4MZP05VV8JTAM2EU"
    aws.secret.access.key: "kWJbGShH+JvbUCzl5PWnPN8+ZAFVzIWejYNgfmC6"
    storage.class: "io.confluent.connect.s3.storage.S3Storage"
    #format.class: "io.confluent.connect.s3.format.avro.AvroFormat"
    format.class: "io.confluent.connect.s3.format.parquet.ParquetFormat"
    key.converter: "io.confluent.connect.avro.AvroConverter"
    key.converter.schema.registry.url: "http://schema-registry-cp-schema-registry:8081"
    value.converter: "io.confluent.connect.avro.AvroConverter"
    value.converter.schema.registry.url: "http://schema-registry-cp-schema-registry:8081"
    enhanced.avro.schema.support: true 
    #schema.generator.class: "io.confluent.connect.storage.hive.schema.DefaultSchemaGenerator"
    partitioner.class: "io.confluent.connect.storage.partitioner.TimeBasedPartitioner"
    path.format: "YYYY/MM/dd/HH"
    locale: "pt_BR"
    timezone: "America/Sao_Paulo"
    partition.duration.ms: 18000
    timestamp.extractor: "Record"
